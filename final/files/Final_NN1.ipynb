{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_NN1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiny880410/helloworld/blob/master/final/files/Final_NN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4YlrfpY_Duh",
        "colab_type": "text"
      },
      "source": [
        "從google drive下載並讀入事前存好的test跟train的csv資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80qpCsI_zJj",
        "colab_type": "code",
        "outputId": "44c2af27-69f6-4c51-a462-3b0c8e4b9779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive')\n",
        "!cp 'gdrive/My Drive/Colab Notebooks/復興南/train data/xtrain1.csv' 'xtrain1.csv'\n",
        "!cp 'gdrive/My Drive/Colab Notebooks/復興南/train data/ytrain1.csv' 'ytrain1.csv'\n",
        "!cp 'gdrive/My Drive/Colab Notebooks/復興南/train data/xtest1.csv' 'xtest1.csv'\n",
        "!cp 'gdrive/My Drive/Colab Notebooks/復興南/train data/ytest1.csv' 'ytest1.csv'\n",
        "!ls\n",
        "X_train = pd.read_csv(\"xtrain1.csv\", header=None)\n",
        "Y_train = pd.read_csv(\"ytrain1.csv\", header=None)\n",
        "X_test = pd.read_csv(\"xtest1.csv\", header=None)\n",
        "Y_test = pd.read_csv(\"ytest1.csv\", header=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data  xtest1.csv  xtrain1.csv  ytest1.csv  ytrain1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnqAyaZ9_CHp",
        "colab_type": "text"
      },
      "source": [
        "從google drive下載上次的模型，就可以分次train data。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL_r8vL50g9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "# 刪除既有模型變數\n",
        "del classifier\n",
        "# 載入模型\n",
        "!cp 'gdrive/My Drive/Colab Notebooks/復興南/train data/classifier1.h5' 'classifier1.h5'\n",
        "classifier = load_model('classifier1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1JYQIpE_cav",
        "colab_type": "text"
      },
      "source": [
        "透過不停地調整，設定適合的結點與層數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWtmalR80De",
        "colab_type": "code",
        "outputId": "cfd0535a-93cb-4e0f-8ed8-1bf0abc1692e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() # Initialising the ANN\n",
        "\n",
        "classifier.add(Dense(units = 18, activation = 'relu', input_dim = 3,kernel_initializer='normal'))\n",
        "classifier.add(Dense(units = 18, activation = 'relu',kernel_initializer='normal'))\n",
        "classifier.add(Dense(units = 9, activation = 'relu',kernel_initializer='normal'))\n",
        "classifier.add(Dense(units = 3, activation = 'relu',kernel_initializer='normal'))\n",
        "classifier.add(Dense(units = 1, activation = 'relu',kernel_initializer='normal'))\n",
        "\n",
        "classifier.compile(loss='mean_squared_error', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn9WPqaP9RmN",
        "colab_type": "text"
      },
      "source": [
        "丟入training data進行訓練，在我們的資料中，以 π2、 π3、 π4為x data，π1為y-data，輸入兩萬多筆資料讓其建構適合的網絡。每次train完都把網絡存下來，下次就不需要重新train。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QlYnFgH9N49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(n):\n",
        "  #classifier.fit(X_train, Y_train, batch_size = 1, epochs = 100)\n",
        "  classifier.fit(X_train, Y_train, validation_split=0.2, epochs=n, batch_size = 100, verbose=2)  \n",
        "  scores = classifier.evaluate(X_train, Y_train)  \n",
        "  print(scores)\n",
        "  \n",
        "  from keras.models import model_from_json\n",
        "  json_string = classifier.to_json() \n",
        "  with open(\"classifier1.config\", \"w\") as text_file:    \n",
        "    text_file.write(json_string)\n",
        "  #權重(W)存檔：以下程式將權重存到 model.weight 檔案。\n",
        "  classifier.save_weights(\"classifier1.weight\")\n",
        "  #同時儲存結構與權重，檔案的類別為HDF5。\n",
        "  from keras.models import load_model\n",
        "\n",
        "  classifier.save('classifier1.h5')  # creates a HDF5 file 'model.h5'\n",
        "\n",
        "  #from google.colab import files\n",
        "  #files.download('classifier1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YT-7PVAZ-_a",
        "colab_type": "code",
        "outputId": "89c95758-0df9-4e92-eafb-809e7721e541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14052
        }
      },
      "source": [
        "for i in range(15):\n",
        "  print(i)\n",
        "  run(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Train on 20479 samples, validate on 5120 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 35861.8851 - acc: 0.0000e+00 - val_loss: 47513.9700 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            " - 0s - loss: 35993.8795 - acc: 0.0000e+00 - val_loss: 48359.1623 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            " - 0s - loss: 35887.8483 - acc: 0.0000e+00 - val_loss: 46270.7179 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            " - 0s - loss: 36095.8901 - acc: 0.0000e+00 - val_loss: 47424.5462 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            " - 0s - loss: 36147.1539 - acc: 0.0000e+00 - val_loss: 45574.8722 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            " - 0s - loss: 36514.7291 - acc: 0.0000e+00 - val_loss: 49732.7758 - val_acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            " - 0s - loss: 35874.4932 - acc: 0.0000e+00 - val_loss: 45192.6133 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            " - 0s - loss: 35671.4557 - acc: 0.0000e+00 - val_loss: 46308.1443 - val_acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            " - 0s - loss: 36237.9149 - acc: 0.0000e+00 - val_loss: 47349.4799 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            " - 0s - loss: 36194.5134 - acc: 0.0000e+00 - val_loss: 45312.7587 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            " - 0s - loss: 35936.6876 - acc: 0.0000e+00 - val_loss: 46660.7803 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            " - 0s - loss: 35778.6742 - acc: 0.0000e+00 - val_loss: 48532.4069 - val_acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            " - 0s - loss: 35763.7894 - acc: 0.0000e+00 - val_loss: 51313.8978 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            " - 0s - loss: 36304.0238 - acc: 0.0000e+00 - val_loss: 50139.3635 - val_acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            " - 0s - loss: 36517.9542 - acc: 0.0000e+00 - val_loss: 44037.3389 - val_acc: 1.9531e-04\n",
            "Epoch 16/100\n",
            " - 0s - loss: 35847.2142 - acc: 0.0000e+00 - val_loss: 48255.1887 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            " - 0s - loss: 35964.2830 - acc: 4.8831e-05 - val_loss: 46249.4998 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            " - 0s - loss: 36184.6640 - acc: 0.0000e+00 - val_loss: 45132.6126 - val_acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            " - 0s - loss: 36268.0540 - acc: 0.0000e+00 - val_loss: 48239.5895 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            " - 0s - loss: 36529.0062 - acc: 0.0000e+00 - val_loss: 44070.4775 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            " - 0s - loss: 36167.1632 - acc: 0.0000e+00 - val_loss: 44714.2972 - val_acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            " - 0s - loss: 36373.8518 - acc: 0.0000e+00 - val_loss: 46906.9238 - val_acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            " - 0s - loss: 35852.4444 - acc: 0.0000e+00 - val_loss: 49925.8703 - val_acc: 1.9531e-04\n",
            "Epoch 24/100\n",
            " - 0s - loss: 36682.3867 - acc: 0.0000e+00 - val_loss: 47305.9052 - val_acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            " - 0s - loss: 35703.4353 - acc: 0.0000e+00 - val_loss: 45911.0389 - val_acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            " - 0s - loss: 35941.7973 - acc: 0.0000e+00 - val_loss: 51556.9744 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            " - 0s - loss: 36409.8157 - acc: 0.0000e+00 - val_loss: 45178.7455 - val_acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            " - 0s - loss: 36010.5789 - acc: 0.0000e+00 - val_loss: 46582.9508 - val_acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            " - 0s - loss: 36118.4918 - acc: 0.0000e+00 - val_loss: 44871.4478 - val_acc: 0.0000e+00\n",
            "Epoch 30/100\n",
            " - 0s - loss: 36270.8213 - acc: 0.0000e+00 - val_loss: 43256.7876 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            " - 0s - loss: 35759.4646 - acc: 0.0000e+00 - val_loss: 43828.3577 - val_acc: 0.0000e+00\n",
            "Epoch 32/100\n",
            " - 0s - loss: 36196.7475 - acc: 0.0000e+00 - val_loss: 48349.9122 - val_acc: 0.0000e+00\n",
            "Epoch 33/100\n",
            " - 0s - loss: 36055.8892 - acc: 0.0000e+00 - val_loss: 46541.6378 - val_acc: 0.0000e+00\n",
            "Epoch 34/100\n",
            " - 0s - loss: 36643.1516 - acc: 4.8831e-05 - val_loss: 44198.4855 - val_acc: 0.0000e+00\n",
            "Epoch 35/100\n",
            " - 0s - loss: 36088.4810 - acc: 0.0000e+00 - val_loss: 42769.4252 - val_acc: 0.0000e+00\n",
            "Epoch 36/100\n",
            " - 0s - loss: 35713.5730 - acc: 0.0000e+00 - val_loss: 46834.2950 - val_acc: 0.0000e+00\n",
            "Epoch 37/100\n",
            " - 0s - loss: 36041.8394 - acc: 0.0000e+00 - val_loss: 45480.2060 - val_acc: 0.0000e+00\n",
            "Epoch 38/100\n",
            " - 0s - loss: 35719.4477 - acc: 4.8831e-05 - val_loss: 43300.1813 - val_acc: 0.0000e+00\n",
            "Epoch 39/100\n",
            " - 0s - loss: 35877.9876 - acc: 0.0000e+00 - val_loss: 46005.2569 - val_acc: 0.0000e+00\n",
            "Epoch 40/100\n",
            " - 0s - loss: 36149.1729 - acc: 0.0000e+00 - val_loss: 51497.6833 - val_acc: 0.0000e+00\n",
            "Epoch 41/100\n",
            " - 0s - loss: 36064.6342 - acc: 0.0000e+00 - val_loss: 48136.4411 - val_acc: 0.0000e+00\n",
            "Epoch 42/100\n",
            " - 0s - loss: 36032.4349 - acc: 4.8831e-05 - val_loss: 46010.2404 - val_acc: 0.0000e+00\n",
            "Epoch 43/100\n",
            " - 0s - loss: 36327.9021 - acc: 0.0000e+00 - val_loss: 47390.2217 - val_acc: 0.0000e+00\n",
            "Epoch 44/100\n",
            " - 0s - loss: 35872.7343 - acc: 0.0000e+00 - val_loss: 46159.5174 - val_acc: 0.0000e+00\n",
            "Epoch 45/100\n",
            " - 0s - loss: 36004.3071 - acc: 0.0000e+00 - val_loss: 45175.9274 - val_acc: 0.0000e+00\n",
            "Epoch 46/100\n",
            " - 0s - loss: 36182.7094 - acc: 0.0000e+00 - val_loss: 45243.2584 - val_acc: 0.0000e+00\n",
            "Epoch 47/100\n",
            " - 0s - loss: 35872.4137 - acc: 4.8831e-05 - val_loss: 47051.5136 - val_acc: 0.0000e+00\n",
            "Epoch 48/100\n",
            " - 0s - loss: 36166.9753 - acc: 0.0000e+00 - val_loss: 43755.4158 - val_acc: 0.0000e+00\n",
            "Epoch 49/100\n",
            " - 0s - loss: 36099.2061 - acc: 0.0000e+00 - val_loss: 45778.2036 - val_acc: 0.0000e+00\n",
            "Epoch 50/100\n",
            " - 0s - loss: 36075.6290 - acc: 0.0000e+00 - val_loss: 44671.1870 - val_acc: 0.0000e+00\n",
            "Epoch 51/100\n",
            " - 0s - loss: 35830.6500 - acc: 0.0000e+00 - val_loss: 43952.1451 - val_acc: 0.0000e+00\n",
            "Epoch 52/100\n",
            " - 0s - loss: 35908.0433 - acc: 0.0000e+00 - val_loss: 44758.5731 - val_acc: 1.9531e-04\n",
            "Epoch 53/100\n",
            " - 0s - loss: 35551.1726 - acc: 0.0000e+00 - val_loss: 46704.6562 - val_acc: 0.0000e+00\n",
            "Epoch 54/100\n",
            " - 0s - loss: 35777.0756 - acc: 4.8831e-05 - val_loss: 49298.2671 - val_acc: 0.0000e+00\n",
            "Epoch 55/100\n",
            " - 0s - loss: 36680.6629 - acc: 0.0000e+00 - val_loss: 51110.9992 - val_acc: 0.0000e+00\n",
            "Epoch 56/100\n",
            " - 0s - loss: 36333.9729 - acc: 0.0000e+00 - val_loss: 46416.2826 - val_acc: 0.0000e+00\n",
            "Epoch 57/100\n",
            " - 0s - loss: 35794.2044 - acc: 4.8831e-05 - val_loss: 48322.7979 - val_acc: 0.0000e+00\n",
            "Epoch 58/100\n",
            " - 0s - loss: 36190.0966 - acc: 0.0000e+00 - val_loss: 51569.8407 - val_acc: 0.0000e+00\n",
            "Epoch 59/100\n",
            " - 0s - loss: 36012.2956 - acc: 0.0000e+00 - val_loss: 47998.3150 - val_acc: 0.0000e+00\n",
            "Epoch 60/100\n",
            " - 0s - loss: 36354.3816 - acc: 0.0000e+00 - val_loss: 47692.4463 - val_acc: 0.0000e+00\n",
            "Epoch 61/100\n",
            " - 0s - loss: 35896.6140 - acc: 0.0000e+00 - val_loss: 45922.9190 - val_acc: 0.0000e+00\n",
            "Epoch 62/100\n",
            " - 0s - loss: 36262.4278 - acc: 0.0000e+00 - val_loss: 44328.3834 - val_acc: 0.0000e+00\n",
            "Epoch 63/100\n",
            " - 0s - loss: 35891.4142 - acc: 0.0000e+00 - val_loss: 44799.8481 - val_acc: 0.0000e+00\n",
            "Epoch 64/100\n",
            " - 0s - loss: 35891.0279 - acc: 0.0000e+00 - val_loss: 43302.2716 - val_acc: 0.0000e+00\n",
            "Epoch 65/100\n",
            " - 0s - loss: 36421.0426 - acc: 0.0000e+00 - val_loss: 45595.3869 - val_acc: 0.0000e+00\n",
            "Epoch 66/100\n",
            " - 0s - loss: 36427.6708 - acc: 0.0000e+00 - val_loss: 45948.8249 - val_acc: 0.0000e+00\n",
            "Epoch 67/100\n",
            " - 0s - loss: 36065.0507 - acc: 0.0000e+00 - val_loss: 48356.9388 - val_acc: 0.0000e+00\n",
            "Epoch 68/100\n",
            " - 0s - loss: 35792.6200 - acc: 0.0000e+00 - val_loss: 44820.0015 - val_acc: 0.0000e+00\n",
            "Epoch 69/100\n",
            " - 0s - loss: 35658.3413 - acc: 0.0000e+00 - val_loss: 47601.4767 - val_acc: 0.0000e+00\n",
            "Epoch 70/100\n",
            " - 0s - loss: 36247.2917 - acc: 0.0000e+00 - val_loss: 46411.6162 - val_acc: 0.0000e+00\n",
            "Epoch 71/100\n",
            " - 0s - loss: 36135.3412 - acc: 0.0000e+00 - val_loss: 45967.2989 - val_acc: 0.0000e+00\n",
            "Epoch 72/100\n",
            " - 0s - loss: 35661.4170 - acc: 0.0000e+00 - val_loss: 44870.3429 - val_acc: 0.0000e+00\n",
            "Epoch 73/100\n",
            " - 0s - loss: 35941.0544 - acc: 0.0000e+00 - val_loss: 46953.8607 - val_acc: 0.0000e+00\n",
            "Epoch 74/100\n",
            " - 0s - loss: 35998.7285 - acc: 0.0000e+00 - val_loss: 43911.2509 - val_acc: 0.0000e+00\n",
            "Epoch 75/100\n",
            " - 0s - loss: 36896.6425 - acc: 4.8831e-05 - val_loss: 52570.1444 - val_acc: 0.0000e+00\n",
            "Epoch 76/100\n",
            " - 0s - loss: 35884.9859 - acc: 0.0000e+00 - val_loss: 44484.4079 - val_acc: 0.0000e+00\n",
            "Epoch 77/100\n",
            " - 0s - loss: 36064.0449 - acc: 0.0000e+00 - val_loss: 45965.6180 - val_acc: 0.0000e+00\n",
            "Epoch 78/100\n",
            " - 0s - loss: 36292.1046 - acc: 0.0000e+00 - val_loss: 45799.9389 - val_acc: 0.0000e+00\n",
            "Epoch 79/100\n",
            " - 0s - loss: 35941.8972 - acc: 0.0000e+00 - val_loss: 47090.6317 - val_acc: 0.0000e+00\n",
            "Epoch 80/100\n",
            " - 0s - loss: 35870.9697 - acc: 0.0000e+00 - val_loss: 45703.7426 - val_acc: 0.0000e+00\n",
            "Epoch 81/100\n",
            " - 0s - loss: 35655.0620 - acc: 0.0000e+00 - val_loss: 45047.8632 - val_acc: 0.0000e+00\n",
            "Epoch 82/100\n",
            " - 0s - loss: 36042.3083 - acc: 0.0000e+00 - val_loss: 47210.9885 - val_acc: 0.0000e+00\n",
            "Epoch 83/100\n",
            " - 0s - loss: 36163.5494 - acc: 0.0000e+00 - val_loss: 43998.5109 - val_acc: 0.0000e+00\n",
            "Epoch 84/100\n",
            " - 0s - loss: 36136.6640 - acc: 0.0000e+00 - val_loss: 49019.1123 - val_acc: 0.0000e+00\n",
            "Epoch 85/100\n",
            " - 0s - loss: 36370.9446 - acc: 0.0000e+00 - val_loss: 46613.4410 - val_acc: 0.0000e+00\n",
            "Epoch 86/100\n",
            " - 0s - loss: 35955.9101 - acc: 0.0000e+00 - val_loss: 45880.4303 - val_acc: 0.0000e+00\n",
            "Epoch 87/100\n",
            " - 0s - loss: 36061.0480 - acc: 0.0000e+00 - val_loss: 47105.3226 - val_acc: 0.0000e+00\n",
            "Epoch 88/100\n",
            " - 0s - loss: 36739.4804 - acc: 0.0000e+00 - val_loss: 44926.0137 - val_acc: 0.0000e+00\n",
            "Epoch 89/100\n",
            " - 0s - loss: 36115.3879 - acc: 0.0000e+00 - val_loss: 46601.7682 - val_acc: 0.0000e+00\n",
            "Epoch 90/100\n",
            " - 0s - loss: 36366.2574 - acc: 0.0000e+00 - val_loss: 44738.2406 - val_acc: 1.9531e-04\n",
            "Epoch 91/100\n",
            " - 0s - loss: 36101.8133 - acc: 0.0000e+00 - val_loss: 45166.7492 - val_acc: 0.0000e+00\n",
            "Epoch 92/100\n",
            " - 0s - loss: 35728.4557 - acc: 0.0000e+00 - val_loss: 48906.9169 - val_acc: 0.0000e+00\n",
            "Epoch 93/100\n",
            " - 0s - loss: 36495.9162 - acc: 0.0000e+00 - val_loss: 47146.4377 - val_acc: 0.0000e+00\n",
            "Epoch 94/100\n",
            " - 0s - loss: 36114.4633 - acc: 0.0000e+00 - val_loss: 47957.3455 - val_acc: 0.0000e+00\n",
            "Epoch 95/100\n",
            " - 0s - loss: 35829.7172 - acc: 0.0000e+00 - val_loss: 49926.2382 - val_acc: 0.0000e+00\n",
            "Epoch 96/100\n",
            " - 0s - loss: 36344.0078 - acc: 0.0000e+00 - val_loss: 47198.8706 - val_acc: 0.0000e+00\n",
            "Epoch 97/100\n",
            " - 0s - loss: 36061.6418 - acc: 0.0000e+00 - val_loss: 48195.0099 - val_acc: 0.0000e+00\n",
            "Epoch 98/100\n",
            " - 0s - loss: 36190.1963 - acc: 0.0000e+00 - val_loss: 45695.8764 - val_acc: 0.0000e+00\n",
            "Epoch 99/100\n",
            " - 0s - loss: 36303.9615 - acc: 0.0000e+00 - val_loss: 46421.2131 - val_acc: 0.0000e+00\n",
            "Epoch 100/100\n",
            " - 0s - loss: 35974.7547 - acc: 0.0000e+00 - val_loss: 43580.0497 - val_acc: 0.0000e+00\n",
            "25599/25599 [==============================] - 0s 17us/step\n",
            "[36424.342598069015, 0.0]\n",
            "1\n",
            "Train on 20479 samples, validate on 5120 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 35798.4584 - acc: 0.0000e+00 - val_loss: 46882.7042 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            " - 0s - loss: 35912.2874 - acc: 0.0000e+00 - val_loss: 48076.9347 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            " - 0s - loss: 36207.9874 - acc: 0.0000e+00 - val_loss: 45243.3755 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            " - 0s - loss: 36217.5400 - acc: 0.0000e+00 - val_loss: 45239.3662 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            " - 0s - loss: 36035.0364 - acc: 0.0000e+00 - val_loss: 50820.7562 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            " - 0s - loss: 36223.1871 - acc: 0.0000e+00 - val_loss: 49744.4577 - val_acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            " - 0s - loss: 36392.4009 - acc: 0.0000e+00 - val_loss: 45758.7215 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            " - 0s - loss: 35800.7660 - acc: 4.8831e-05 - val_loss: 48186.4869 - val_acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            " - 0s - loss: 36111.6314 - acc: 0.0000e+00 - val_loss: 45724.3015 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            " - 0s - loss: 36239.8362 - acc: 0.0000e+00 - val_loss: 45246.2018 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            " - 0s - loss: 35630.7439 - acc: 0.0000e+00 - val_loss: 48713.3335 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            " - 0s - loss: 36458.3941 - acc: 4.8831e-05 - val_loss: 45562.9596 - val_acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            " - 0s - loss: 36186.2668 - acc: 0.0000e+00 - val_loss: 53444.1073 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            " - 0s - loss: 36133.9180 - acc: 0.0000e+00 - val_loss: 45621.2299 - val_acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            " - 0s - loss: 35807.8454 - acc: 0.0000e+00 - val_loss: 42385.9544 - val_acc: 0.0000e+00\n",
            "Epoch 16/100\n",
            " - 0s - loss: 35561.7375 - acc: 0.0000e+00 - val_loss: 46345.0354 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            " - 0s - loss: 35945.0646 - acc: 0.0000e+00 - val_loss: 45341.0146 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            " - 0s - loss: 35881.7021 - acc: 0.0000e+00 - val_loss: 44997.4746 - val_acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            " - 0s - loss: 36758.7672 - acc: 0.0000e+00 - val_loss: 45871.7121 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            " - 0s - loss: 35890.5043 - acc: 0.0000e+00 - val_loss: 45959.5123 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            " - 0s - loss: 35727.7607 - acc: 0.0000e+00 - val_loss: 50530.8190 - val_acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            " - 0s - loss: 35702.5391 - acc: 0.0000e+00 - val_loss: 45116.2473 - val_acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            " - 0s - loss: 36098.7427 - acc: 0.0000e+00 - val_loss: 44805.5852 - val_acc: 0.0000e+00\n",
            "Epoch 24/100\n",
            " - 0s - loss: 35597.9964 - acc: 0.0000e+00 - val_loss: 44103.1124 - val_acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            " - 0s - loss: 35815.6179 - acc: 0.0000e+00 - val_loss: 47264.2750 - val_acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            " - 0s - loss: 36013.6244 - acc: 4.8831e-05 - val_loss: 43797.7927 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            " - 0s - loss: 35711.7283 - acc: 0.0000e+00 - val_loss: 43316.3637 - val_acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            " - 0s - loss: 35669.5164 - acc: 0.0000e+00 - val_loss: 49404.7928 - val_acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            " - 0s - loss: 36038.0487 - acc: 0.0000e+00 - val_loss: 45036.9495 - val_acc: 0.0000e+00\n",
            "Epoch 30/100\n",
            " - 0s - loss: 36129.1512 - acc: 0.0000e+00 - val_loss: 46873.8952 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            " - 0s - loss: 35851.8035 - acc: 4.8831e-05 - val_loss: 44309.0429 - val_acc: 0.0000e+00\n",
            "Epoch 32/100\n",
            " - 0s - loss: 35874.4806 - acc: 0.0000e+00 - val_loss: 44470.0462 - val_acc: 0.0000e+00\n",
            "Epoch 33/100\n",
            " - 0s - loss: 36178.3631 - acc: 0.0000e+00 - val_loss: 45406.0623 - val_acc: 0.0000e+00\n",
            "Epoch 34/100\n",
            " - 0s - loss: 35935.2059 - acc: 0.0000e+00 - val_loss: 45309.7506 - val_acc: 0.0000e+00\n",
            "Epoch 35/100\n",
            " - 0s - loss: 36568.7665 - acc: 0.0000e+00 - val_loss: 53348.9802 - val_acc: 0.0000e+00\n",
            "Epoch 36/100\n",
            " - 0s - loss: 36120.7305 - acc: 0.0000e+00 - val_loss: 45611.8305 - val_acc: 0.0000e+00\n",
            "Epoch 37/100\n",
            " - 0s - loss: 36106.6039 - acc: 0.0000e+00 - val_loss: 44179.7046 - val_acc: 0.0000e+00\n",
            "Epoch 38/100\n",
            " - 0s - loss: 35672.8716 - acc: 0.0000e+00 - val_loss: 49599.8246 - val_acc: 0.0000e+00\n",
            "Epoch 39/100\n",
            " - 0s - loss: 35819.9664 - acc: 0.0000e+00 - val_loss: 51406.7715 - val_acc: 0.0000e+00\n",
            "Epoch 40/100\n",
            " - 0s - loss: 36097.3071 - acc: 0.0000e+00 - val_loss: 44083.3133 - val_acc: 0.0000e+00\n",
            "Epoch 41/100\n",
            " - 0s - loss: 36144.1379 - acc: 0.0000e+00 - val_loss: 43499.5576 - val_acc: 0.0000e+00\n",
            "Epoch 42/100\n",
            " - 0s - loss: 35910.0735 - acc: 0.0000e+00 - val_loss: 44203.3744 - val_acc: 0.0000e+00\n",
            "Epoch 43/100\n",
            " - 0s - loss: 35438.1268 - acc: 0.0000e+00 - val_loss: 45947.3158 - val_acc: 0.0000e+00\n",
            "Epoch 44/100\n",
            " - 0s - loss: 35799.8519 - acc: 0.0000e+00 - val_loss: 46629.4842 - val_acc: 0.0000e+00\n",
            "Epoch 45/100\n",
            " - 0s - loss: 35921.7562 - acc: 0.0000e+00 - val_loss: 46285.0834 - val_acc: 0.0000e+00\n",
            "Epoch 46/100\n",
            " - 0s - loss: 36104.2868 - acc: 4.8831e-05 - val_loss: 48467.5163 - val_acc: 0.0000e+00\n",
            "Epoch 47/100\n",
            " - 0s - loss: 36212.5119 - acc: 0.0000e+00 - val_loss: 46352.5005 - val_acc: 0.0000e+00\n",
            "Epoch 48/100\n",
            " - 0s - loss: 35894.1653 - acc: 0.0000e+00 - val_loss: 46206.3873 - val_acc: 0.0000e+00\n",
            "Epoch 49/100\n",
            " - 0s - loss: 35866.2741 - acc: 0.0000e+00 - val_loss: 46259.0430 - val_acc: 0.0000e+00\n",
            "Epoch 50/100\n",
            " - 0s - loss: 36038.2975 - acc: 0.0000e+00 - val_loss: 51877.2467 - val_acc: 0.0000e+00\n",
            "Epoch 51/100\n",
            " - 0s - loss: 36057.4941 - acc: 0.0000e+00 - val_loss: 47341.6260 - val_acc: 0.0000e+00\n",
            "Epoch 52/100\n",
            " - 0s - loss: 36109.9913 - acc: 0.0000e+00 - val_loss: 46962.7090 - val_acc: 0.0000e+00\n",
            "Epoch 53/100\n",
            " - 0s - loss: 36283.1604 - acc: 0.0000e+00 - val_loss: 45341.3168 - val_acc: 0.0000e+00\n",
            "Epoch 54/100\n",
            " - 0s - loss: 36128.0885 - acc: 0.0000e+00 - val_loss: 42598.6223 - val_acc: 0.0000e+00\n",
            "Epoch 55/100\n",
            " - 0s - loss: 35638.5113 - acc: 0.0000e+00 - val_loss: 52458.8490 - val_acc: 0.0000e+00\n",
            "Epoch 56/100\n",
            " - 0s - loss: 36234.4542 - acc: 0.0000e+00 - val_loss: 46461.6256 - val_acc: 0.0000e+00\n",
            "Epoch 57/100\n",
            " - 0s - loss: 36307.0200 - acc: 0.0000e+00 - val_loss: 49503.3912 - val_acc: 0.0000e+00\n",
            "Epoch 58/100\n",
            " - 0s - loss: 35937.8264 - acc: 0.0000e+00 - val_loss: 46844.0912 - val_acc: 0.0000e+00\n",
            "Epoch 59/100\n",
            " - 0s - loss: 35907.3715 - acc: 0.0000e+00 - val_loss: 44055.5787 - val_acc: 0.0000e+00\n",
            "Epoch 60/100\n",
            " - 0s - loss: 35729.6698 - acc: 0.0000e+00 - val_loss: 43002.4437 - val_acc: 0.0000e+00\n",
            "Epoch 61/100\n",
            " - 0s - loss: 36011.0977 - acc: 4.8831e-05 - val_loss: 46815.5401 - val_acc: 0.0000e+00\n",
            "Epoch 62/100\n",
            " - 0s - loss: 35906.2484 - acc: 0.0000e+00 - val_loss: 45178.7914 - val_acc: 0.0000e+00\n",
            "Epoch 63/100\n",
            " - 0s - loss: 35817.4138 - acc: 0.0000e+00 - val_loss: 48618.1130 - val_acc: 0.0000e+00\n",
            "Epoch 64/100\n",
            " - 0s - loss: 35863.9075 - acc: 0.0000e+00 - val_loss: 48960.9677 - val_acc: 0.0000e+00\n",
            "Epoch 65/100\n",
            " - 0s - loss: 36450.1382 - acc: 0.0000e+00 - val_loss: 47458.8259 - val_acc: 0.0000e+00\n",
            "Epoch 66/100\n",
            " - 0s - loss: 37110.8101 - acc: 0.0000e+00 - val_loss: 46310.4887 - val_acc: 0.0000e+00\n",
            "Epoch 67/100\n",
            " - 0s - loss: 36125.8032 - acc: 4.8831e-05 - val_loss: 47263.3081 - val_acc: 0.0000e+00\n",
            "Epoch 68/100\n",
            " - 0s - loss: 35630.8710 - acc: 4.8831e-05 - val_loss: 46424.0399 - val_acc: 0.0000e+00\n",
            "Epoch 69/100\n",
            " - 0s - loss: 36155.1120 - acc: 0.0000e+00 - val_loss: 48031.6519 - val_acc: 0.0000e+00\n",
            "Epoch 70/100\n",
            " - 0s - loss: 36374.4611 - acc: 0.0000e+00 - val_loss: 49126.6955 - val_acc: 0.0000e+00\n",
            "Epoch 71/100\n",
            " - 0s - loss: 35649.7820 - acc: 0.0000e+00 - val_loss: 48707.6454 - val_acc: 0.0000e+00\n",
            "Epoch 72/100\n",
            " - 0s - loss: 35657.7721 - acc: 0.0000e+00 - val_loss: 48527.0041 - val_acc: 0.0000e+00\n",
            "Epoch 73/100\n",
            " - 0s - loss: 35923.8906 - acc: 0.0000e+00 - val_loss: 44062.5223 - val_acc: 0.0000e+00\n",
            "Epoch 74/100\n",
            " - 0s - loss: 35924.3768 - acc: 0.0000e+00 - val_loss: 45926.8082 - val_acc: 0.0000e+00\n",
            "Epoch 75/100\n",
            " - 0s - loss: 35878.9120 - acc: 0.0000e+00 - val_loss: 48895.6639 - val_acc: 0.0000e+00\n",
            "Epoch 76/100\n",
            " - 0s - loss: 36138.9342 - acc: 0.0000e+00 - val_loss: 47607.3898 - val_acc: 0.0000e+00\n",
            "Epoch 77/100\n",
            " - 0s - loss: 35760.6690 - acc: 0.0000e+00 - val_loss: 46031.4271 - val_acc: 0.0000e+00\n",
            "Epoch 78/100\n",
            " - 0s - loss: 35901.6558 - acc: 0.0000e+00 - val_loss: 45968.6530 - val_acc: 0.0000e+00\n",
            "Epoch 79/100\n",
            " - 0s - loss: 35825.7678 - acc: 4.8831e-05 - val_loss: 46143.8892 - val_acc: 0.0000e+00\n",
            "Epoch 80/100\n",
            " - 0s - loss: 35633.3903 - acc: 0.0000e+00 - val_loss: 48417.4168 - val_acc: 0.0000e+00\n",
            "Epoch 81/100\n",
            " - 0s - loss: 36402.4528 - acc: 0.0000e+00 - val_loss: 47158.6640 - val_acc: 0.0000e+00\n",
            "Epoch 82/100\n",
            " - 0s - loss: 35483.4280 - acc: 0.0000e+00 - val_loss: 43763.0335 - val_acc: 0.0000e+00\n",
            "Epoch 83/100\n",
            " - 0s - loss: 36023.4526 - acc: 0.0000e+00 - val_loss: 45231.3895 - val_acc: 0.0000e+00\n",
            "Epoch 84/100\n",
            " - 0s - loss: 35455.5961 - acc: 0.0000e+00 - val_loss: 44727.8524 - val_acc: 0.0000e+00\n",
            "Epoch 85/100\n",
            " - 0s - loss: 36114.8326 - acc: 4.8831e-05 - val_loss: 46988.2774 - val_acc: 0.0000e+00\n",
            "Epoch 86/100\n",
            " - 0s - loss: 36068.7368 - acc: 0.0000e+00 - val_loss: 49307.0653 - val_acc: 0.0000e+00\n",
            "Epoch 87/100\n",
            " - 0s - loss: 36290.8855 - acc: 0.0000e+00 - val_loss: 42567.9875 - val_acc: 0.0000e+00\n",
            "Epoch 88/100\n",
            " - 0s - loss: 35836.6673 - acc: 0.0000e+00 - val_loss: 44482.3079 - val_acc: 0.0000e+00\n",
            "Epoch 89/100\n",
            " - 0s - loss: 35793.5587 - acc: 0.0000e+00 - val_loss: 47034.0638 - val_acc: 0.0000e+00\n",
            "Epoch 90/100\n",
            " - 0s - loss: 35907.0284 - acc: 0.0000e+00 - val_loss: 48689.2554 - val_acc: 1.9531e-04\n",
            "Epoch 91/100\n",
            " - 0s - loss: 36186.7704 - acc: 0.0000e+00 - val_loss: 55223.5120 - val_acc: 0.0000e+00\n",
            "Epoch 92/100\n",
            " - 0s - loss: 36000.6588 - acc: 0.0000e+00 - val_loss: 49388.4760 - val_acc: 0.0000e+00\n",
            "Epoch 93/100\n",
            " - 0s - loss: 35967.6137 - acc: 0.0000e+00 - val_loss: 49960.9085 - val_acc: 0.0000e+00\n",
            "Epoch 94/100\n",
            " - 0s - loss: 36078.7778 - acc: 4.8831e-05 - val_loss: 44991.4044 - val_acc: 0.0000e+00\n",
            "Epoch 95/100\n",
            " - 0s - loss: 35594.1907 - acc: 0.0000e+00 - val_loss: 43505.9122 - val_acc: 0.0000e+00\n",
            "Epoch 96/100\n",
            " - 0s - loss: 36050.9414 - acc: 0.0000e+00 - val_loss: 44901.1683 - val_acc: 0.0000e+00\n",
            "Epoch 97/100\n",
            " - 0s - loss: 36467.3838 - acc: 0.0000e+00 - val_loss: 51802.4086 - val_acc: 0.0000e+00\n",
            "Epoch 98/100\n",
            " - 0s - loss: 36427.0114 - acc: 0.0000e+00 - val_loss: 52582.7016 - val_acc: 0.0000e+00\n",
            "Epoch 99/100\n",
            " - 0s - loss: 35852.1779 - acc: 0.0000e+00 - val_loss: 46833.4950 - val_acc: 0.0000e+00\n",
            "Epoch 100/100\n",
            " - 0s - loss: 35876.8844 - acc: 0.0000e+00 - val_loss: 44089.6605 - val_acc: 0.0000e+00\n",
            "25599/25599 [==============================] - 1s 22us/step\n",
            "[36503.023158672884, 0.0]\n",
            "2\n",
            "Train on 20479 samples, validate on 5120 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 35522.8830 - acc: 0.0000e+00 - val_loss: 43499.5937 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            " - 0s - loss: 36027.3552 - acc: 0.0000e+00 - val_loss: 44228.3361 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            " - 0s - loss: 36132.7034 - acc: 4.8831e-05 - val_loss: 46245.7220 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            " - 0s - loss: 35918.1116 - acc: 0.0000e+00 - val_loss: 46566.5714 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            " - 0s - loss: 36155.8369 - acc: 0.0000e+00 - val_loss: 45887.6463 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            " - 0s - loss: 36382.6869 - acc: 0.0000e+00 - val_loss: 50280.3782 - val_acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            " - 0s - loss: 35977.3778 - acc: 0.0000e+00 - val_loss: 46255.4379 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            " - 0s - loss: 36062.4535 - acc: 0.0000e+00 - val_loss: 50781.1393 - val_acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            " - 0s - loss: 35843.6595 - acc: 0.0000e+00 - val_loss: 48737.3352 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            " - 0s - loss: 36242.2109 - acc: 0.0000e+00 - val_loss: 44587.2453 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            " - 0s - loss: 35919.7918 - acc: 0.0000e+00 - val_loss: 46537.6566 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            " - 0s - loss: 35976.1447 - acc: 0.0000e+00 - val_loss: 45478.3395 - val_acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            " - 0s - loss: 35877.1996 - acc: 0.0000e+00 - val_loss: 50395.7822 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            " - 0s - loss: 35840.8709 - acc: 4.8831e-05 - val_loss: 47997.8033 - val_acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            " - 0s - loss: 35662.5160 - acc: 4.8831e-05 - val_loss: 43989.6423 - val_acc: 0.0000e+00\n",
            "Epoch 16/100\n",
            " - 0s - loss: 36017.1089 - acc: 4.8831e-05 - val_loss: 45175.1197 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            " - 0s - loss: 35752.9017 - acc: 0.0000e+00 - val_loss: 45926.1698 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            " - 0s - loss: 35684.7825 - acc: 0.0000e+00 - val_loss: 46247.6229 - val_acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            " - 0s - loss: 36746.7692 - acc: 0.0000e+00 - val_loss: 46016.7474 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            " - 0s - loss: 36259.3333 - acc: 0.0000e+00 - val_loss: 46367.9909 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            " - 0s - loss: 35791.2412 - acc: 0.0000e+00 - val_loss: 48633.5907 - val_acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            " - 0s - loss: 35893.6196 - acc: 0.0000e+00 - val_loss: 47730.7832 - val_acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            " - 0s - loss: 36130.5436 - acc: 0.0000e+00 - val_loss: 46331.7117 - val_acc: 0.0000e+00\n",
            "Epoch 24/100\n",
            " - 0s - loss: 35613.5508 - acc: 0.0000e+00 - val_loss: 44990.5956 - val_acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            " - 0s - loss: 36693.5417 - acc: 0.0000e+00 - val_loss: 47030.8227 - val_acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            " - 0s - loss: 35907.8508 - acc: 0.0000e+00 - val_loss: 46574.5845 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            " - 0s - loss: 36065.9059 - acc: 4.8831e-05 - val_loss: 42825.8672 - val_acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            " - 0s - loss: 35766.7370 - acc: 0.0000e+00 - val_loss: 54288.7080 - val_acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            " - 0s - loss: 35893.3530 - acc: 0.0000e+00 - val_loss: 46090.3547 - val_acc: 0.0000e+00\n",
            "Epoch 30/100\n",
            " - 0s - loss: 35859.6580 - acc: 4.8831e-05 - val_loss: 50348.7292 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            " - 0s - loss: 36236.1303 - acc: 0.0000e+00 - val_loss: 47783.4145 - val_acc: 0.0000e+00\n",
            "Epoch 32/100\n",
            " - 0s - loss: 36433.3555 - acc: 0.0000e+00 - val_loss: 47348.7487 - val_acc: 0.0000e+00\n",
            "Epoch 33/100\n",
            " - 0s - loss: 35978.9177 - acc: 0.0000e+00 - val_loss: 47936.9090 - val_acc: 0.0000e+00\n",
            "Epoch 34/100\n",
            " - 0s - loss: 35834.2680 - acc: 0.0000e+00 - val_loss: 46248.3746 - val_acc: 0.0000e+00\n",
            "Epoch 35/100\n",
            " - 0s - loss: 35799.3949 - acc: 0.0000e+00 - val_loss: 48901.8958 - val_acc: 0.0000e+00\n",
            "Epoch 36/100\n",
            " - 0s - loss: 35900.5363 - acc: 0.0000e+00 - val_loss: 43977.1786 - val_acc: 0.0000e+00\n",
            "Epoch 37/100\n",
            " - 0s - loss: 36069.6159 - acc: 0.0000e+00 - val_loss: 44531.6649 - val_acc: 0.0000e+00\n",
            "Epoch 38/100\n",
            " - 0s - loss: 35793.7976 - acc: 0.0000e+00 - val_loss: 45706.7595 - val_acc: 0.0000e+00\n",
            "Epoch 39/100\n",
            " - 0s - loss: 35792.5770 - acc: 0.0000e+00 - val_loss: 43857.2192 - val_acc: 1.9531e-04\n",
            "Epoch 40/100\n",
            " - 0s - loss: 36029.4238 - acc: 0.0000e+00 - val_loss: 50487.0767 - val_acc: 0.0000e+00\n",
            "Epoch 41/100\n",
            " - 0s - loss: 36272.2540 - acc: 0.0000e+00 - val_loss: 43173.5033 - val_acc: 0.0000e+00\n",
            "Epoch 42/100\n",
            " - 0s - loss: 36581.0692 - acc: 0.0000e+00 - val_loss: 45624.8830 - val_acc: 0.0000e+00\n",
            "Epoch 43/100\n",
            " - 0s - loss: 36110.5605 - acc: 0.0000e+00 - val_loss: 47095.4194 - val_acc: 0.0000e+00\n",
            "Epoch 44/100\n",
            " - 0s - loss: 35958.9196 - acc: 0.0000e+00 - val_loss: 50399.6063 - val_acc: 0.0000e+00\n",
            "Epoch 45/100\n",
            " - 0s - loss: 35538.1943 - acc: 0.0000e+00 - val_loss: 48891.3610 - val_acc: 0.0000e+00\n",
            "Epoch 46/100\n",
            " - 0s - loss: 36241.7533 - acc: 0.0000e+00 - val_loss: 48427.6281 - val_acc: 0.0000e+00\n",
            "Epoch 47/100\n",
            " - 0s - loss: 35560.8765 - acc: 0.0000e+00 - val_loss: 45673.9685 - val_acc: 0.0000e+00\n",
            "Epoch 48/100\n",
            " - 0s - loss: 35789.3816 - acc: 0.0000e+00 - val_loss: 44770.9499 - val_acc: 0.0000e+00\n",
            "Epoch 49/100\n",
            " - 0s - loss: 36075.9756 - acc: 0.0000e+00 - val_loss: 49780.9488 - val_acc: 0.0000e+00\n",
            "Epoch 50/100\n",
            " - 0s - loss: 36422.7502 - acc: 0.0000e+00 - val_loss: 44765.9474 - val_acc: 0.0000e+00\n",
            "Epoch 51/100\n",
            " - 0s - loss: 36206.4537 - acc: 0.0000e+00 - val_loss: 44501.1263 - val_acc: 0.0000e+00\n",
            "Epoch 52/100\n",
            " - 0s - loss: 35983.6854 - acc: 0.0000e+00 - val_loss: 47898.9818 - val_acc: 0.0000e+00\n",
            "Epoch 53/100\n",
            " - 0s - loss: 35886.6420 - acc: 0.0000e+00 - val_loss: 48961.0951 - val_acc: 0.0000e+00\n",
            "Epoch 54/100\n",
            " - 0s - loss: 36052.3824 - acc: 0.0000e+00 - val_loss: 48788.0104 - val_acc: 0.0000e+00\n",
            "Epoch 55/100\n",
            " - 0s - loss: 35853.5511 - acc: 0.0000e+00 - val_loss: 45630.6005 - val_acc: 0.0000e+00\n",
            "Epoch 56/100\n",
            " - 0s - loss: 36003.3387 - acc: 0.0000e+00 - val_loss: 44944.3180 - val_acc: 0.0000e+00\n",
            "Epoch 57/100\n",
            " - 0s - loss: 35774.6381 - acc: 0.0000e+00 - val_loss: 46222.8990 - val_acc: 0.0000e+00\n",
            "Epoch 58/100\n",
            " - 0s - loss: 36098.2432 - acc: 0.0000e+00 - val_loss: 49024.3668 - val_acc: 0.0000e+00\n",
            "Epoch 59/100\n",
            " - 0s - loss: 36273.6014 - acc: 0.0000e+00 - val_loss: 45045.8254 - val_acc: 0.0000e+00\n",
            "Epoch 60/100\n",
            " - 0s - loss: 36018.8320 - acc: 0.0000e+00 - val_loss: 46077.6982 - val_acc: 0.0000e+00\n",
            "Epoch 61/100\n",
            " - 0s - loss: 36194.4048 - acc: 0.0000e+00 - val_loss: 43796.6921 - val_acc: 0.0000e+00\n",
            "Epoch 62/100\n",
            " - 0s - loss: 35725.2374 - acc: 0.0000e+00 - val_loss: 43823.8035 - val_acc: 0.0000e+00\n",
            "Epoch 63/100\n",
            " - 0s - loss: 36052.8231 - acc: 4.8831e-05 - val_loss: 46735.6668 - val_acc: 0.0000e+00\n",
            "Epoch 64/100\n",
            " - 0s - loss: 35747.3075 - acc: 0.0000e+00 - val_loss: 51988.6562 - val_acc: 0.0000e+00\n",
            "Epoch 65/100\n",
            " - 0s - loss: 36583.1919 - acc: 0.0000e+00 - val_loss: 47357.7025 - val_acc: 0.0000e+00\n",
            "Epoch 66/100\n",
            " - 0s - loss: 35933.0886 - acc: 0.0000e+00 - val_loss: 46281.5076 - val_acc: 0.0000e+00\n",
            "Epoch 67/100\n",
            " - 0s - loss: 35809.6302 - acc: 0.0000e+00 - val_loss: 44198.6872 - val_acc: 0.0000e+00\n",
            "Epoch 68/100\n",
            " - 0s - loss: 35790.3913 - acc: 0.0000e+00 - val_loss: 44169.0282 - val_acc: 0.0000e+00\n",
            "Epoch 69/100\n",
            " - 0s - loss: 36089.7240 - acc: 0.0000e+00 - val_loss: 47584.5001 - val_acc: 0.0000e+00\n",
            "Epoch 70/100\n",
            " - 0s - loss: 35997.2477 - acc: 0.0000e+00 - val_loss: 45772.4718 - val_acc: 0.0000e+00\n",
            "Epoch 71/100\n",
            " - 0s - loss: 35760.6236 - acc: 0.0000e+00 - val_loss: 47882.9838 - val_acc: 0.0000e+00\n",
            "Epoch 72/100\n",
            " - 0s - loss: 35448.0520 - acc: 0.0000e+00 - val_loss: 48896.5159 - val_acc: 0.0000e+00\n",
            "Epoch 73/100\n",
            " - 0s - loss: 36347.4739 - acc: 0.0000e+00 - val_loss: 46760.9114 - val_acc: 0.0000e+00\n",
            "Epoch 74/100\n",
            " - 0s - loss: 35799.9387 - acc: 0.0000e+00 - val_loss: 49541.7655 - val_acc: 0.0000e+00\n",
            "Epoch 75/100\n",
            " - 0s - loss: 35829.0453 - acc: 0.0000e+00 - val_loss: 46212.6461 - val_acc: 0.0000e+00\n",
            "Epoch 76/100\n",
            " - 0s - loss: 36438.2718 - acc: 0.0000e+00 - val_loss: 45532.7256 - val_acc: 0.0000e+00\n",
            "Epoch 77/100\n",
            " - 0s - loss: 35759.5395 - acc: 0.0000e+00 - val_loss: 48281.6693 - val_acc: 0.0000e+00\n",
            "Epoch 78/100\n",
            " - 0s - loss: 35649.6584 - acc: 0.0000e+00 - val_loss: 46057.1377 - val_acc: 0.0000e+00\n",
            "Epoch 79/100\n",
            " - 0s - loss: 35813.3149 - acc: 0.0000e+00 - val_loss: 48392.4567 - val_acc: 0.0000e+00\n",
            "Epoch 80/100\n",
            " - 0s - loss: 35570.5517 - acc: 0.0000e+00 - val_loss: 48533.7902 - val_acc: 0.0000e+00\n",
            "Epoch 81/100\n",
            " - 0s - loss: 35776.1310 - acc: 9.7661e-05 - val_loss: 45020.8589 - val_acc: 0.0000e+00\n",
            "Epoch 82/100\n",
            " - 0s - loss: 35601.2517 - acc: 0.0000e+00 - val_loss: 43058.3223 - val_acc: 0.0000e+00\n",
            "Epoch 83/100\n",
            " - 0s - loss: 35766.8730 - acc: 0.0000e+00 - val_loss: 46264.5116 - val_acc: 0.0000e+00\n",
            "Epoch 84/100\n",
            " - 0s - loss: 35796.1414 - acc: 0.0000e+00 - val_loss: 43658.0993 - val_acc: 0.0000e+00\n",
            "Epoch 85/100\n",
            " - 0s - loss: 35543.3003 - acc: 4.8831e-05 - val_loss: 45327.3914 - val_acc: 0.0000e+00\n",
            "Epoch 86/100\n",
            " - 0s - loss: 35958.5463 - acc: 0.0000e+00 - val_loss: 44704.3310 - val_acc: 0.0000e+00\n",
            "Epoch 87/100\n",
            " - 0s - loss: 35925.1044 - acc: 0.0000e+00 - val_loss: 45788.1440 - val_acc: 0.0000e+00\n",
            "Epoch 88/100\n",
            " - 0s - loss: 35775.6166 - acc: 0.0000e+00 - val_loss: 44091.7615 - val_acc: 0.0000e+00\n",
            "Epoch 89/100\n",
            " - 0s - loss: 35888.4618 - acc: 4.8831e-05 - val_loss: 48836.1574 - val_acc: 0.0000e+00\n",
            "Epoch 90/100\n",
            " - 0s - loss: 36151.6751 - acc: 4.8831e-05 - val_loss: 45258.6775 - val_acc: 0.0000e+00\n",
            "Epoch 91/100\n",
            " - 0s - loss: 36137.0023 - acc: 0.0000e+00 - val_loss: 45850.7137 - val_acc: 0.0000e+00\n",
            "Epoch 92/100\n",
            " - 0s - loss: 36385.2618 - acc: 0.0000e+00 - val_loss: 45369.8300 - val_acc: 0.0000e+00\n",
            "Epoch 93/100\n",
            " - 0s - loss: 35832.3429 - acc: 0.0000e+00 - val_loss: 48472.3186 - val_acc: 0.0000e+00\n",
            "Epoch 94/100\n",
            " - 0s - loss: 35995.3982 - acc: 0.0000e+00 - val_loss: 48929.3149 - val_acc: 0.0000e+00\n",
            "Epoch 95/100\n",
            " - 0s - loss: 35958.4283 - acc: 0.0000e+00 - val_loss: 44956.2113 - val_acc: 0.0000e+00\n",
            "Epoch 96/100\n",
            " - 0s - loss: 35753.4088 - acc: 0.0000e+00 - val_loss: 45246.7587 - val_acc: 0.0000e+00\n",
            "Epoch 97/100\n",
            " - 0s - loss: 35672.0721 - acc: 0.0000e+00 - val_loss: 44501.3547 - val_acc: 0.0000e+00\n",
            "Epoch 98/100\n",
            " - 0s - loss: 35839.7712 - acc: 0.0000e+00 - val_loss: 46942.1271 - val_acc: 0.0000e+00\n",
            "Epoch 99/100\n",
            " - 0s - loss: 36064.7152 - acc: 0.0000e+00 - val_loss: 44889.9924 - val_acc: 0.0000e+00\n",
            "Epoch 100/100\n",
            " - 0s - loss: 35754.5296 - acc: 0.0000e+00 - val_loss: 47340.4949 - val_acc: 0.0000e+00\n",
            "25599/25599 [==============================] - 0s 19us/step\n",
            "[37400.508863986084, 0.0]\n",
            "3\n",
            "Train on 20479 samples, validate on 5120 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 36330.2527 - acc: 0.0000e+00 - val_loss: 52341.5752 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            " - 0s - loss: 36072.1016 - acc: 0.0000e+00 - val_loss: 45515.4457 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            " - 0s - loss: 35702.9013 - acc: 0.0000e+00 - val_loss: 48875.4159 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            " - 0s - loss: 35864.8405 - acc: 0.0000e+00 - val_loss: 45753.7352 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            " - 0s - loss: 35465.1418 - acc: 0.0000e+00 - val_loss: 44408.6840 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            " - 0s - loss: 35618.8439 - acc: 0.0000e+00 - val_loss: 48905.5104 - val_acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            " - 0s - loss: 35965.0168 - acc: 0.0000e+00 - val_loss: 44865.7452 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            " - 0s - loss: 36108.0171 - acc: 0.0000e+00 - val_loss: 46185.2528 - val_acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            " - 0s - loss: 35693.8344 - acc: 0.0000e+00 - val_loss: 44826.7441 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            " - 0s - loss: 36343.7404 - acc: 0.0000e+00 - val_loss: 43944.7692 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            " - 0s - loss: 35910.8142 - acc: 0.0000e+00 - val_loss: 42081.8701 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            " - 0s - loss: 35996.5854 - acc: 0.0000e+00 - val_loss: 46101.4289 - val_acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            " - 0s - loss: 35976.1568 - acc: 0.0000e+00 - val_loss: 44240.7568 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            " - 0s - loss: 35946.9166 - acc: 0.0000e+00 - val_loss: 45353.0068 - val_acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            " - 0s - loss: 35829.0060 - acc: 0.0000e+00 - val_loss: 48325.8009 - val_acc: 0.0000e+00\n",
            "Epoch 16/100\n",
            " - 0s - loss: 36173.0599 - acc: 0.0000e+00 - val_loss: 49259.7582 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            " - 0s - loss: 36003.0602 - acc: 0.0000e+00 - val_loss: 47394.4441 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            " - 0s - loss: 35766.1221 - acc: 0.0000e+00 - val_loss: 43239.0118 - val_acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            " - 0s - loss: 35856.5095 - acc: 0.0000e+00 - val_loss: 45970.9419 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            " - 0s - loss: 35585.4976 - acc: 0.0000e+00 - val_loss: 44288.5283 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            " - 0s - loss: 36292.6885 - acc: 0.0000e+00 - val_loss: 50939.9191 - val_acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            " - 0s - loss: 35786.2932 - acc: 0.0000e+00 - val_loss: 48980.5573 - val_acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            " - 0s - loss: 35908.0400 - acc: 4.8831e-05 - val_loss: 46330.9518 - val_acc: 0.0000e+00\n",
            "Epoch 24/100\n",
            " - 0s - loss: 35646.4552 - acc: 0.0000e+00 - val_loss: 51359.0056 - val_acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            " - 0s - loss: 36504.7274 - acc: 0.0000e+00 - val_loss: 48656.5899 - val_acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            " - 0s - loss: 35930.0425 - acc: 9.7661e-05 - val_loss: 48175.8153 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            " - 0s - loss: 35750.4823 - acc: 0.0000e+00 - val_loss: 44393.5973 - val_acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            " - 0s - loss: 35942.4069 - acc: 4.8831e-05 - val_loss: 44062.8445 - val_acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            " - 0s - loss: 35700.3552 - acc: 0.0000e+00 - val_loss: 47058.1846 - val_acc: 0.0000e+00\n",
            "Epoch 30/100\n",
            " - 0s - loss: 36316.6276 - acc: 0.0000e+00 - val_loss: 42667.6462 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            " - 0s - loss: 35983.2981 - acc: 0.0000e+00 - val_loss: 48139.1511 - val_acc: 0.0000e+00\n",
            "Epoch 32/100\n",
            " - 0s - loss: 35379.1091 - acc: 0.0000e+00 - val_loss: 44370.2937 - val_acc: 0.0000e+00\n",
            "Epoch 33/100\n",
            " - 0s - loss: 36126.6663 - acc: 0.0000e+00 - val_loss: 43192.9979 - val_acc: 0.0000e+00\n",
            "Epoch 34/100\n",
            " - 0s - loss: 36301.9197 - acc: 4.8831e-05 - val_loss: 45550.1099 - val_acc: 0.0000e+00\n",
            "Epoch 35/100\n",
            " - 0s - loss: 35860.1862 - acc: 0.0000e+00 - val_loss: 47596.1722 - val_acc: 0.0000e+00\n",
            "Epoch 36/100\n",
            " - 0s - loss: 36129.9457 - acc: 0.0000e+00 - val_loss: 46880.5749 - val_acc: 0.0000e+00\n",
            "Epoch 37/100\n",
            " - 0s - loss: 36174.0853 - acc: 0.0000e+00 - val_loss: 45490.1866 - val_acc: 0.0000e+00\n",
            "Epoch 38/100\n",
            " - 0s - loss: 35780.6109 - acc: 0.0000e+00 - val_loss: 46451.9586 - val_acc: 0.0000e+00\n",
            "Epoch 39/100\n",
            " - 0s - loss: 35958.2694 - acc: 0.0000e+00 - val_loss: 45532.4471 - val_acc: 0.0000e+00\n",
            "Epoch 40/100\n",
            " - 0s - loss: 36589.4486 - acc: 0.0000e+00 - val_loss: 47276.7784 - val_acc: 0.0000e+00\n",
            "Epoch 41/100\n",
            " - 0s - loss: 36365.2882 - acc: 0.0000e+00 - val_loss: 48573.7309 - val_acc: 0.0000e+00\n",
            "Epoch 42/100\n",
            " - 0s - loss: 36004.4125 - acc: 0.0000e+00 - val_loss: 46566.9055 - val_acc: 0.0000e+00\n",
            "Epoch 43/100\n",
            " - 0s - loss: 35858.0222 - acc: 0.0000e+00 - val_loss: 45979.7583 - val_acc: 0.0000e+00\n",
            "Epoch 44/100\n",
            " - 0s - loss: 35514.7350 - acc: 0.0000e+00 - val_loss: 47415.0605 - val_acc: 0.0000e+00\n",
            "Epoch 45/100\n",
            " - 0s - loss: 35905.5841 - acc: 0.0000e+00 - val_loss: 48722.3618 - val_acc: 0.0000e+00\n",
            "Epoch 46/100\n",
            " - 0s - loss: 35976.1556 - acc: 0.0000e+00 - val_loss: 45433.4775 - val_acc: 0.0000e+00\n",
            "Epoch 47/100\n",
            " - 0s - loss: 36373.1303 - acc: 0.0000e+00 - val_loss: 43871.1389 - val_acc: 0.0000e+00\n",
            "Epoch 48/100\n",
            " - 0s - loss: 36655.6242 - acc: 0.0000e+00 - val_loss: 44272.1679 - val_acc: 0.0000e+00\n",
            "Epoch 49/100\n",
            " - 0s - loss: 35639.7745 - acc: 0.0000e+00 - val_loss: 46315.2242 - val_acc: 0.0000e+00\n",
            "Epoch 50/100\n",
            " - 0s - loss: 35675.3917 - acc: 0.0000e+00 - val_loss: 44174.7033 - val_acc: 0.0000e+00\n",
            "Epoch 51/100\n",
            " - 0s - loss: 36226.0472 - acc: 0.0000e+00 - val_loss: 43891.3503 - val_acc: 0.0000e+00\n",
            "Epoch 52/100\n",
            " - 0s - loss: 35666.4497 - acc: 0.0000e+00 - val_loss: 43284.7403 - val_acc: 0.0000e+00\n",
            "Epoch 53/100\n",
            " - 0s - loss: 35549.1802 - acc: 0.0000e+00 - val_loss: 49247.5722 - val_acc: 0.0000e+00\n",
            "Epoch 54/100\n",
            " - 0s - loss: 35690.4588 - acc: 0.0000e+00 - val_loss: 44767.2760 - val_acc: 0.0000e+00\n",
            "Epoch 55/100\n",
            " - 0s - loss: 36032.7556 - acc: 4.8831e-05 - val_loss: 46486.4607 - val_acc: 0.0000e+00\n",
            "Epoch 56/100\n",
            " - 0s - loss: 35638.8195 - acc: 0.0000e+00 - val_loss: 46020.5279 - val_acc: 0.0000e+00\n",
            "Epoch 57/100\n",
            " - 0s - loss: 35926.5675 - acc: 0.0000e+00 - val_loss: 47718.5548 - val_acc: 0.0000e+00\n",
            "Epoch 58/100\n",
            " - 0s - loss: 36197.9510 - acc: 0.0000e+00 - val_loss: 45856.9002 - val_acc: 0.0000e+00\n",
            "Epoch 59/100\n",
            " - 0s - loss: 35913.7019 - acc: 0.0000e+00 - val_loss: 44415.0809 - val_acc: 0.0000e+00\n",
            "Epoch 60/100\n",
            " - 0s - loss: 36202.2997 - acc: 0.0000e+00 - val_loss: 47012.6499 - val_acc: 1.9531e-04\n",
            "Epoch 61/100\n",
            " - 0s - loss: 36482.3985 - acc: 0.0000e+00 - val_loss: 45190.2517 - val_acc: 0.0000e+00\n",
            "Epoch 62/100\n",
            " - 0s - loss: 36163.2767 - acc: 0.0000e+00 - val_loss: 46250.0698 - val_acc: 0.0000e+00\n",
            "Epoch 63/100\n",
            " - 0s - loss: 35973.2370 - acc: 0.0000e+00 - val_loss: 47830.1396 - val_acc: 0.0000e+00\n",
            "Epoch 64/100\n",
            " - 0s - loss: 36208.9448 - acc: 0.0000e+00 - val_loss: 48057.8536 - val_acc: 0.0000e+00\n",
            "Epoch 65/100\n",
            " - 0s - loss: 36064.1621 - acc: 0.0000e+00 - val_loss: 44647.7335 - val_acc: 0.0000e+00\n",
            "Epoch 66/100\n",
            " - 0s - loss: 36004.7433 - acc: 0.0000e+00 - val_loss: 48649.0499 - val_acc: 0.0000e+00\n",
            "Epoch 67/100\n",
            " - 0s - loss: 35852.7266 - acc: 0.0000e+00 - val_loss: 48634.5113 - val_acc: 0.0000e+00\n",
            "Epoch 68/100\n",
            " - 0s - loss: 35616.6200 - acc: 0.0000e+00 - val_loss: 44576.0553 - val_acc: 0.0000e+00\n",
            "Epoch 69/100\n",
            " - 0s - loss: 36154.9933 - acc: 0.0000e+00 - val_loss: 45052.9172 - val_acc: 0.0000e+00\n",
            "Epoch 70/100\n",
            " - 0s - loss: 35506.3363 - acc: 0.0000e+00 - val_loss: 51710.2028 - val_acc: 0.0000e+00\n",
            "Epoch 71/100\n",
            " - 0s - loss: 36003.6627 - acc: 4.8831e-05 - val_loss: 50882.8604 - val_acc: 0.0000e+00\n",
            "Epoch 72/100\n",
            " - 0s - loss: 35752.9766 - acc: 0.0000e+00 - val_loss: 44308.3461 - val_acc: 0.0000e+00\n",
            "Epoch 73/100\n",
            " - 0s - loss: 35979.6792 - acc: 0.0000e+00 - val_loss: 46761.6015 - val_acc: 0.0000e+00\n",
            "Epoch 74/100\n",
            " - 0s - loss: 35752.6433 - acc: 0.0000e+00 - val_loss: 46008.5532 - val_acc: 0.0000e+00\n",
            "Epoch 75/100\n",
            " - 0s - loss: 36236.7107 - acc: 0.0000e+00 - val_loss: 45981.1865 - val_acc: 0.0000e+00\n",
            "Epoch 76/100\n",
            " - 0s - loss: 36390.2556 - acc: 0.0000e+00 - val_loss: 43738.0979 - val_acc: 0.0000e+00\n",
            "Epoch 77/100\n",
            " - 0s - loss: 36016.6821 - acc: 0.0000e+00 - val_loss: 42907.9776 - val_acc: 0.0000e+00\n",
            "Epoch 78/100\n",
            " - 0s - loss: 35716.9627 - acc: 0.0000e+00 - val_loss: 44198.7463 - val_acc: 0.0000e+00\n",
            "Epoch 79/100\n",
            " - 0s - loss: 35732.3149 - acc: 0.0000e+00 - val_loss: 44809.2343 - val_acc: 0.0000e+00\n",
            "Epoch 80/100\n",
            " - 0s - loss: 35914.3337 - acc: 0.0000e+00 - val_loss: 45008.8742 - val_acc: 0.0000e+00\n",
            "Epoch 81/100\n",
            " - 0s - loss: 35702.6646 - acc: 0.0000e+00 - val_loss: 44825.3961 - val_acc: 0.0000e+00\n",
            "Epoch 82/100\n",
            " - 0s - loss: 35944.5655 - acc: 0.0000e+00 - val_loss: 46704.0108 - val_acc: 0.0000e+00\n",
            "Epoch 83/100\n",
            " - 0s - loss: 36053.0120 - acc: 0.0000e+00 - val_loss: 44298.5875 - val_acc: 0.0000e+00\n",
            "Epoch 84/100\n",
            " - 0s - loss: 36305.4420 - acc: 0.0000e+00 - val_loss: 51317.3883 - val_acc: 0.0000e+00\n",
            "Epoch 85/100\n",
            " - 0s - loss: 36047.7101 - acc: 0.0000e+00 - val_loss: 46505.5335 - val_acc: 0.0000e+00\n",
            "Epoch 86/100\n",
            " - 0s - loss: 35917.4750 - acc: 4.8831e-05 - val_loss: 50556.0731 - val_acc: 0.0000e+00\n",
            "Epoch 87/100\n",
            " - 0s - loss: 36284.9951 - acc: 4.8831e-05 - val_loss: 46477.3953 - val_acc: 0.0000e+00\n",
            "Epoch 88/100\n",
            " - 0s - loss: 35857.1578 - acc: 0.0000e+00 - val_loss: 46496.0461 - val_acc: 0.0000e+00\n",
            "Epoch 89/100\n",
            " - 0s - loss: 36014.0266 - acc: 0.0000e+00 - val_loss: 47228.7630 - val_acc: 0.0000e+00\n",
            "Epoch 90/100\n",
            " - 0s - loss: 35473.0987 - acc: 0.0000e+00 - val_loss: 44501.6111 - val_acc: 0.0000e+00\n",
            "Epoch 91/100\n",
            " - 0s - loss: 36023.2134 - acc: 0.0000e+00 - val_loss: 45398.7946 - val_acc: 0.0000e+00\n",
            "Epoch 92/100\n",
            " - 0s - loss: 35692.2580 - acc: 0.0000e+00 - val_loss: 47949.4220 - val_acc: 0.0000e+00\n",
            "Epoch 93/100\n",
            " - 0s - loss: 36008.4730 - acc: 4.8831e-05 - val_loss: 48035.2461 - val_acc: 0.0000e+00\n",
            "Epoch 94/100\n",
            " - 0s - loss: 35338.9363 - acc: 0.0000e+00 - val_loss: 48028.2262 - val_acc: 0.0000e+00\n",
            "Epoch 95/100\n",
            " - 0s - loss: 36690.9485 - acc: 0.0000e+00 - val_loss: 46796.3402 - val_acc: 0.0000e+00\n",
            "Epoch 96/100\n",
            " - 0s - loss: 36402.0755 - acc: 0.0000e+00 - val_loss: 44972.6773 - val_acc: 0.0000e+00\n",
            "Epoch 97/100\n",
            " - 0s - loss: 36087.5495 - acc: 0.0000e+00 - val_loss: 45391.0232 - val_acc: 0.0000e+00\n",
            "Epoch 98/100\n",
            " - 0s - loss: 35869.6664 - acc: 0.0000e+00 - val_loss: 55957.5517 - val_acc: 0.0000e+00\n",
            "Epoch 99/100\n",
            " - 0s - loss: 36356.7604 - acc: 0.0000e+00 - val_loss: 51622.4370 - val_acc: 0.0000e+00\n",
            "Epoch 100/100\n",
            " - 0s - loss: 35994.4177 - acc: 0.0000e+00 - val_loss: 46297.1139 - val_acc: 0.0000e+00\n",
            "25599/25599 [==============================] - 0s 17us/step\n",
            "[37088.336493323106, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrnGgtfn9gsE",
        "colab_type": "text"
      },
      "source": [
        "試著放入新的(沒有被辨識過的資料)進行預測，以下為預測出之pi1。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEaG0Tkx9fUU",
        "colab_type": "code",
        "outputId": "4867f4b1-7055-48c0-f2c2-82feee7456c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "print(Y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 992.0276 ]\n",
            " [1107.0199 ]\n",
            " [ 861.89355]\n",
            " [1876.4949 ]\n",
            " [ 917.99524]\n",
            " [ 872.58264]\n",
            " [1575.7316 ]\n",
            " [ 936.6817 ]\n",
            " [ 908.20294]\n",
            " [1323.1349 ]\n",
            " [1254.7222 ]\n",
            " [1756.6674 ]\n",
            " [ 547.4966 ]\n",
            " [1245.0969 ]\n",
            " [ 981.008  ]\n",
            " [ 416.84442]\n",
            " [ 699.12946]\n",
            " [ 678.6125 ]\n",
            " [ 875.5904 ]\n",
            " [ 543.0908 ]\n",
            " [ 782.2655 ]\n",
            " [ 875.1358 ]\n",
            " [1058.4683 ]\n",
            " [1071.9181 ]\n",
            " [1650.8899 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQK3Qo9h97OW",
        "colab_type": "text"
      },
      "source": [
        "將輸出資料與原資料進行比較並計算誤差，並定義誤差在10%以內為成功，反之則為失敗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he_2VHJ_9yC1",
        "colab_type": "code",
        "outputId": "e238dc9b-0468-46c3-fdba-4b96fa2534ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "total = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "for i in Y_pred:\n",
        "  a = (Y_test.at[total,0] - i)/Y_test.at[total,0]\n",
        "  print(\"%d,%d%%\"%(i,a*100))\n",
        "  if( abs((Y_test.at[total,0] - i)/Y_test.at[total,0])<=0.1):\n",
        "    correct=correct+1\n",
        "  else:\n",
        "    wrong=wrong+1\n",
        "  total=total+1\n",
        "print(\"Total \" + str(total))\n",
        "print(\"Correct \" + str(correct))\n",
        "print(\"Wrong \" + str(wrong))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "992,14%\n",
            "1107,3%\n",
            "861,6%\n",
            "1876,-3%\n",
            "917,-1%\n",
            "872,2%\n",
            "1575,1%\n",
            "936,-5%\n",
            "908,9%\n",
            "1323,-7%\n",
            "1254,8%\n",
            "1756,2%\n",
            "547,5%\n",
            "1245,-10%\n",
            "981,19%\n",
            "416,0%\n",
            "699,0%\n",
            "678,0%\n",
            "875,2%\n",
            "543,9%\n",
            "782,2%\n",
            "875,27%\n",
            "1058,-2%\n",
            "1071,4%\n",
            "1650,-6%\n",
            "Total 25\n",
            "Correct 21\n",
            "Wrong 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oaKb-YHB-zI",
        "colab_type": "text"
      },
      "source": [
        "如果training的結果是可接受的就將模型上傳至google drive中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQLZH_2oCSBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.save('gdrive/My Drive/Colab Notebooks/復興南/train data/classifier1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcrtLkWB1Bg2",
        "colab_type": "code",
        "outputId": "4e28e490-f6f2-416f-aa22-833c5805ef75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "#!rm classifier1.h5\n",
        "#!rm classifier1.config\n",
        "#!rm classifier1.weight\n",
        "#file = files.upload()\n",
        "#!rm xtrain1.csv\n",
        "#!rm ytrain1.csv\n",
        "#!rm xtest1.csv\n",
        "#!rm ytest1.csv\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier1.config  classifier1.weight\tsample_data  xtrain1.csv  ytrain1.csv\n",
            "classifier1.h5\t    gdrive\t\txtest1.csv   ytest1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}